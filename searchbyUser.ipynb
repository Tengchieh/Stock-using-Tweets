{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan through stock related tweets and derive sentiments by each user.\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import pprint\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "company_list = []\n",
    "frequency = {}\n",
    "with open('SP500.csv') as SP500csv:\n",
    "    reader = csv.DictReader(SP500csv)\n",
    "    for row in reader:\n",
    "        company_list.append(row['Symbol'])\n",
    "\n",
    "buy_keywords = []\n",
    "sell_keywords = []\n",
    "with open('keyword.csv') as keyword:\n",
    "    reader = csv.DictReader(keyword)\n",
    "    for row in reader:\n",
    "        buy_keywords.append(row['Buy'])\n",
    "        if row['Sell']:\n",
    "            sell_keywords.append(row['Sell'])\n",
    "        \n",
    "#Create sentiment accumulation for different dates\n",
    "day = 30\n",
    "n_company = len(company_list)\n",
    "acc_sentiment = [0] * n_company\n",
    "for i in range(n_company):\n",
    "    acc_sentiment[i] = [0] * day\n",
    "    \n",
    "arr = np.array(acc_sentiment)\n",
    "\n",
    "#Initialize acc_sentiment files.\n",
    "path = os.path.join(\"Extra_Storage\", \"ArchiveteamTest\", \"2015\", \"11\")\n",
    "with open(os.path.join(path, \"id_list.txt\" )) as id_list:\n",
    "    reader = id_list.readlines()\n",
    "    idList = [x.strip() for x in reader]\n",
    "    n_authors = len(idList)\n",
    "    for user in idList:\n",
    "        #print(arr)\n",
    "        np.savetxt(os.path.join(path, 'User_Sentiment', 'acc_sentiment_2015_11_' + user + '.csv'), arr, fmt='%i', delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for dirPath, dirNames, fileNames in os.walk(path):\n",
    "    for file in fileNames:\n",
    "        if file.endswith(\"json\"):\n",
    "            filepath = os.path.join(dirPath, file)\n",
    "            with open(filepath) as json_data:\n",
    "                data=[]\n",
    "                for line in json_data:\n",
    "                    try:\n",
    "                        data.append(json.loads(line))\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "                for tweet in data:\n",
    "                    if 'text' in tweet:\n",
    "                        tweet_lower = tweet['text'].lower()\n",
    "                        company_index = -1\n",
    "                        for company in company_list:\n",
    "                            company_index+=1\n",
    "                            company_tag = ' $' + company + ' '\n",
    "                            if company_tag.lower() in tweet_lower:\n",
    "                                sentiment = 0\n",
    "                                for buy_keyword in buy_keywords:\n",
    "                                    if buy_keyword in tweet_lower:\n",
    "                                        sentiment+=1\n",
    "                                for sell_keyword in sell_keywords:\n",
    "                                    if sell_keyword in tweet_lower:\n",
    "                                        sentiment-=1\n",
    "                                if sentiment==0:\n",
    "                                    break\n",
    "                                else:\n",
    "                                    if 'created_at' in tweet:\n",
    "                                        second = (datetime.strptime(tweet['created_at'],'%a %b %d %H:%M:%S +%f %Y')- datetime(2015, 11, 1)).total_seconds()\n",
    "                                        date = math.ceil(second/86400) - 1            \n",
    "                                    else:\n",
    "                                        break\n",
    "                                        \n",
    "                                    user_sentiment_file = os.path.join(path, \"User_Sentiment\", \"acc_sentiment_2015_11_\" + str(tweet['user']['id']) + \".csv\")\n",
    "                                    user_sentiment = np.genfromtxt(user_sentiment_file, delimiter=',')\n",
    "                                    if date ==  user_sentiment.shape[1]:\n",
    "                                        date -= 1\n",
    "                                    if sentiment > 0:\n",
    "                                        user_sentiment[company_index][date]+=1\n",
    "                                    else:\n",
    "                                        user_sentiment[company_index][date]-=1\n",
    "                                    #print(user_sentiment)        \n",
    "                                    arr = np.array(user_sentiment)\n",
    "                                    #np.savetxt(user_sentiment_file, arr, fmt='%i', header=dates, comments='', delimiter=',')\n",
    "                                    np.savetxt(user_sentiment_file, arr, fmt='%i', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate dates\n",
    "dates = []\n",
    "for thedate in range(1, day+1):\n",
    "    dates.append('11/'+ str(thedate) + '/2015')\n",
    "    #dates += '4/' + str(thedate) + '/2016, '\n",
    "    #dates += '4/30/2016' #Add final day\n",
    "\n",
    "sentimentpath = os.path.join(\"Extra_Storage\", \"ArchiveteamTest\", \"2015\", \"11\", \"User_Sentiment\")\n",
    "for dirPath, dirNames, fileNames in os.walk(sentimentpath):\n",
    "    for file in fileNames:\n",
    "        filepath = os.path.join(dirPath, file)\n",
    "        with open(filepath) as outcsv:\n",
    "            r = csv.reader(outcsv)\n",
    "            data = [line for line in r]\n",
    "        with open(filepath, 'w', newline='') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow(dates)\n",
    "            writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
